{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/darshandugar2004/XrayImageClassification-TransferLearning/blob/main/Brain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKMyq_5mEO8r"
      },
      "outputs": [],
      "source": [
        "!unzip -q converted_images.zip -d /content/brain_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jq-38mmzF-8k",
        "outputId": "7830693a-f1fe-4fd7-f110-5d178277957d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-GAUbqtfGt6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/brain_dataset/converted_images\"\n",
        "\n",
        "# Define image size and batch size\n",
        "img_size = (128, 128)\n",
        "batch_size = 64\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,      # Increase rotation for more variation\n",
        "    width_shift_range=0.2,  # Increase shift range\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,   # Add flipping for more diversity\n",
        "    vertical_flip=True,     # Add vertical flip\n",
        "    shear_range=0.2,        # Introduce shearing\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Load Training and Validation Data\n",
        "train_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    dataset_path,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='grayscale',\n",
        "    subset='validation',\n",
        "    shuffle=False  # Important for correct label extraction\n",
        ")\n",
        "\n",
        "# Get Class Names\n",
        "class_names = list(train_data.class_indices.keys())\n",
        "print(\"Class Names:\", class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7lQXNspG64G",
        "outputId": "ff509c6e-aee5-449d-8399-66bbee4da218"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2452 images belonging to 3 classes.\n",
            "Found 612 images belonging to 3 classes.\n",
            "Class Names: ['class_0', 'class_1', 'class_2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau,ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=\"/content/drive/MyDrive/brain.h5\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    verbose=1\n",
        ")\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(128, 128, 1)),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(32, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Conv2D(256, (3,3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(2,2),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(len(class_names), activation='softmax', dtype='float32')  # Output layer\n",
        "])\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
        "\n",
        "# Enable XLA for faster training\n",
        "tf.config.optimizer.set_jit(True)\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(train_data, validation_data=val_data, epochs=25, callbacks=[lr_scheduler,checkpoint])\n",
        "\n",
        "\n",
        "#model.save(\"brain_tumor_model.h5\")\n",
        "#print(\"Model saved successfully!\")\n",
        "\n",
        "# Evaluate Model\n",
        "val_loss, val_acc = model.evaluate(val_data)\n",
        "print(f\"Validation Accuracy: {val_acc:.2%}\")\n",
        "\n",
        "# Get True Labels\n",
        "true_labels = val_data.classes\n",
        "\n",
        "# Get Predicted Labels\n",
        "predictions = model.predict(val_data)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Print Classification Report (Precision, Recall, F1-Score)\n",
        "report = classification_report(true_labels, predicted_labels, target_names=class_names)\n",
        "print(\"\\nClassification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGEWiNk2HFsQ",
        "outputId": "118e9a4a-df39-4d8e-dfe5-62d526544ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 345ms/step - accuracy: 0.4525 - loss: 1.4933\n",
            "Epoch 1: val_loss improved from inf to 1.66397, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 501ms/step - accuracy: 0.4537 - loss: 1.4890 - val_accuracy: 0.3039 - val_loss: 1.6640 - learning_rate: 5.0000e-04\n",
            "Epoch 2/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.5775 - loss: 1.0666\n",
            "Epoch 2: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.5784 - loss: 1.0648 - val_accuracy: 0.3039 - val_loss: 4.4878 - learning_rate: 5.0000e-04\n",
            "Epoch 3/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 0.6830 - loss: 0.8432\n",
            "Epoch 3: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 262ms/step - accuracy: 0.6832 - loss: 0.8428 - val_accuracy: 0.3039 - val_loss: 6.5131 - learning_rate: 5.0000e-04\n",
            "Epoch 4/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7096 - loss: 0.7541\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 234ms/step - accuracy: 0.7097 - loss: 0.7534 - val_accuracy: 0.3039 - val_loss: 7.5054 - learning_rate: 5.0000e-04\n",
            "Epoch 5/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7410 - loss: 0.6540\n",
            "Epoch 5: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 236ms/step - accuracy: 0.7413 - loss: 0.6532 - val_accuracy: 0.3039 - val_loss: 6.6245 - learning_rate: 2.5000e-04\n",
            "Epoch 6/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7534 - loss: 0.6417\n",
            "Epoch 6: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 215ms/step - accuracy: 0.7536 - loss: 0.6406 - val_accuracy: 0.3039 - val_loss: 9.3773 - learning_rate: 2.5000e-04\n",
            "Epoch 7/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 0.7777 - loss: 0.5620\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\n",
            "Epoch 7: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 237ms/step - accuracy: 0.7778 - loss: 0.5620 - val_accuracy: 0.3039 - val_loss: 4.8383 - learning_rate: 2.5000e-04\n",
            "Epoch 8/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7863 - loss: 0.5341\n",
            "Epoch 8: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 309ms/step - accuracy: 0.7864 - loss: 0.5338 - val_accuracy: 0.3039 - val_loss: 7.0210 - learning_rate: 1.2500e-04\n",
            "Epoch 9/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7970 - loss: 0.4955\n",
            "Epoch 9: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - accuracy: 0.7972 - loss: 0.4950 - val_accuracy: 0.3235 - val_loss: 4.4543 - learning_rate: 1.2500e-04\n",
            "Epoch 10/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8320 - loss: 0.4217\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\n",
            "Epoch 10: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 238ms/step - accuracy: 0.8321 - loss: 0.4218 - val_accuracy: 0.4183 - val_loss: 2.7835 - learning_rate: 1.2500e-04\n",
            "Epoch 11/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.8168 - loss: 0.4342\n",
            "Epoch 11: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 236ms/step - accuracy: 0.8169 - loss: 0.4342 - val_accuracy: 0.3824 - val_loss: 3.4465 - learning_rate: 6.2500e-05\n",
            "Epoch 12/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 0.8394 - loss: 0.4139\n",
            "Epoch 12: val_loss did not improve from 1.66397\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 273ms/step - accuracy: 0.8390 - loss: 0.4143 - val_accuracy: 0.4297 - val_loss: 2.9686 - learning_rate: 6.2500e-05\n",
            "Epoch 13/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8360 - loss: 0.4041\n",
            "Epoch 13: val_loss improved from 1.66397 to 0.89131, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 262ms/step - accuracy: 0.8360 - loss: 0.4041 - val_accuracy: 0.7288 - val_loss: 0.8913 - learning_rate: 6.2500e-05\n",
            "Epoch 14/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.8297 - loss: 0.4214\n",
            "Epoch 14: val_loss improved from 0.89131 to 0.63850, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 240ms/step - accuracy: 0.8297 - loss: 0.4211 - val_accuracy: 0.7402 - val_loss: 0.6385 - learning_rate: 6.2500e-05\n",
            "Epoch 15/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 0.8462 - loss: 0.3824\n",
            "Epoch 15: val_loss did not improve from 0.63850\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 274ms/step - accuracy: 0.8460 - loss: 0.3828 - val_accuracy: 0.7745 - val_loss: 0.6678 - learning_rate: 6.2500e-05\n",
            "Epoch 16/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8497 - loss: 0.3841\n",
            "Epoch 16: val_loss did not improve from 0.63850\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.8496 - loss: 0.3842 - val_accuracy: 0.7288 - val_loss: 0.7717 - learning_rate: 6.2500e-05\n",
            "Epoch 17/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8444 - loss: 0.3938\n",
            "Epoch 17: val_loss improved from 0.63850 to 0.41217, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 263ms/step - accuracy: 0.8445 - loss: 0.3939 - val_accuracy: 0.8366 - val_loss: 0.4122 - learning_rate: 6.2500e-05\n",
            "Epoch 18/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8431 - loss: 0.4239\n",
            "Epoch 18: val_loss did not improve from 0.41217\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 237ms/step - accuracy: 0.8433 - loss: 0.4233 - val_accuracy: 0.7843 - val_loss: 0.5368 - learning_rate: 6.2500e-05\n",
            "Epoch 19/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8734 - loss: 0.3312\n",
            "Epoch 19: val_loss improved from 0.41217 to 0.36669, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.8729 - loss: 0.3320 - val_accuracy: 0.8252 - val_loss: 0.3667 - learning_rate: 6.2500e-05\n",
            "Epoch 20/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step - accuracy: 0.8505 - loss: 0.3743\n",
            "Epoch 20: val_loss improved from 0.36669 to 0.34092, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 237ms/step - accuracy: 0.8509 - loss: 0.3736 - val_accuracy: 0.8644 - val_loss: 0.3409 - learning_rate: 6.2500e-05\n",
            "Epoch 21/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.8622 - loss: 0.3263\n",
            "Epoch 21: val_loss improved from 0.34092 to 0.31896, saving model to /content/drive/MyDrive/brain.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 299ms/step - accuracy: 0.8622 - loss: 0.3269 - val_accuracy: 0.8595 - val_loss: 0.3190 - learning_rate: 6.2500e-05\n",
            "Epoch 22/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8509 - loss: 0.3575\n",
            "Epoch 22: val_loss did not improve from 0.31896\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 216ms/step - accuracy: 0.8510 - loss: 0.3575 - val_accuracy: 0.8448 - val_loss: 0.3608 - learning_rate: 6.2500e-05\n",
            "Epoch 23/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8704 - loss: 0.3212\n",
            "Epoch 23: val_loss did not improve from 0.31896\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.8703 - loss: 0.3217 - val_accuracy: 0.7157 - val_loss: 0.7686 - learning_rate: 6.2500e-05\n",
            "Epoch 24/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.8711 - loss: 0.3174\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.31896\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 292ms/step - accuracy: 0.8711 - loss: 0.3177 - val_accuracy: 0.8742 - val_loss: 0.3242 - learning_rate: 6.2500e-05\n",
            "Epoch 25/25\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8708 - loss: 0.3066\n",
            "Epoch 25: val_loss did not improve from 0.31896\n",
            "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 236ms/step - accuracy: 0.8709 - loss: 0.3069 - val_accuracy: 0.8464 - val_loss: 0.3402 - learning_rate: 3.1250e-05\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.8099 - loss: 0.4129\n",
            "Validation Accuracy: 85.95%\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.82      0.67      0.73       141\n",
            "     class_1       0.84      0.96      0.90       285\n",
            "     class_2       0.92      0.85      0.89       186\n",
            "\n",
            "    accuracy                           0.86       612\n",
            "   macro avg       0.86      0.83      0.84       612\n",
            "weighted avg       0.86      0.86      0.86       612\n",
            "\n"
          ]
        }
      ]
    }
  ]
}